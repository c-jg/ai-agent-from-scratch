{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8d019e-8c4c-4d3c-94f2-211e057c9665",
   "metadata": {},
   "source": [
    "# Local AI Agent from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3cf25-bfc3-43c9-bad3-818e2cf09a2c",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build a simple function-calling AI agent from scratch using the OpenAI-compatible API format and a local vLLM inference server. It shows how to structure prompts, parse model outputs, and route function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97bf043-5fca-4bbe-a17e-32b5883ca199",
   "metadata": {},
   "source": [
    "> **NOTE:** Before starting, launch a vLLM server in a separate terminal using your model of choice: `vllm serve <model>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4750f03-8bff-47ac-92ab-9634bba43e5f",
   "metadata": {},
   "source": [
    "I am using [Salesforce/xLAM-2-3b-fc-r](https://huggingface.co/Salesforce/xLAM-2-3b-fc-r) due to its small size and high ranking on the [Berkeley Function-Calling Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard.html).  The model is running locally on my Nvidia RTX 3060.\n",
    "\n",
    "Launch command: `vllm serve Salesforce/xLAM-2-3b-fc-r --enable-auto-tool-choice --tool-parser-plugin ./xlam_tool_call_parser.py --tool-call-parser xlam --tensor-parallel-size 1 --dtype float16 --gpu-memory-utilization 0.8`\n",
    "\n",
    "The full vLLM launch instructions for this particular model can be found in the [_**Using vLLM for Inference**_ section](https://huggingface.co/Salesforce/xLAM-2-3b-fc-r#using-vllm-for-inference) on the model's HugginngFace page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123f422c-73f9-43e3-98f8-d5aedf25fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff6b63-f707-46f1-a0d8-62dbd8a5b573",
   "metadata": {},
   "source": [
    "### Set vLLM endpoint URL and create client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b670f6-6bac-4e62-a8e6-eaec63e60c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salesforce/xLAM-2-3b-fc-r\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"null\")\n",
    "models = client.models.list()\n",
    "model_id = models.data[0].id\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0656d7-63d2-4c98-9533-78abf1e49f4d",
   "metadata": {},
   "source": [
    "### Test Chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a539a7e-ced0-4ea3-aa61-f9ea83935a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three NBA teams:\n",
      "1. Los Angeles Lakers\n",
      "2. Boston Celtics\n",
      "3. Golden State Warriors"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"List three NBA teams\"},\n",
    "]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=model_id,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in chat_completion:\n",
    "    delta = chunk.choices[0].delta.content or \"\"\n",
    "    print(delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f705b-5c9c-46f3-af70-84d599fffc66",
   "metadata": {},
   "source": [
    "# Control Flow Overview\n",
    "**1.** The user submits a query to the LLM.\n",
    "\n",
    "**2.** The LLM determines if a tool call is necessary.  If so, it will decide which function to call and specify the input parameters. \n",
    "\n",
    "- The model will only return this information, it will not actually call the function itself.\n",
    "    - For example, if the query is `\"What's the weather like in SF?\"` the LLM should specify to call the function named `get_current_weather` with the parameters `{\"city\": \"San Francisco\", \"state\": \"CA\"}`\n",
    "\n",
    "**3.** We use the JSON function call to run the actual `get_current_weather` function with the LLM's provided arguments.\n",
    "\n",
    "**4.** The tool call and context is passed back to the LLM to generate a final response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a9947-2ec8-4011-bebf-455db189a77e",
   "metadata": {},
   "source": [
    "### Define tools in OpenAI function calling schema\n",
    "\n",
    "Two functions schemas are defined: `get_current_weather` and `send_email`.  Each function schema tells the model what the function does and what input arguments are expected. More details on function schemas can be found in the [OpenAI API docs](https://platform.openai.com/docs/guides/function-calling#defining-functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad63859-b0e6-42c1-b6c8-d0514cb132d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city to find the weather for, e.g. 'San Francisco'\",\n",
    "                    },\n",
    "                    \"state\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"the two-letter abbreviation for the state that the city is\"\n",
    "                        \" in, e.g. 'CA' which would mean 'California'\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\", \"state\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"send_email\",\n",
    "            \"description\": \"Send an email to a given recipient with a subject and message.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"to\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The recipient email address.\"\n",
    "                    },\n",
    "                    \"subject\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Email subject line.\"\n",
    "                    },\n",
    "                    \"body\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Body of the email message.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"to\",\n",
    "                    \"subject\",\n",
    "                    \"body\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed55470c-20ca-4e73-b7b6-ad6d0a8e6cde",
   "metadata": {},
   "source": [
    "### Python function definitions for tool execution\n",
    "\n",
    "The actual Python functions that perform the tasks described in the tool specifications, fetching current weather data and sending an email, are defined here. These functions are called by the model when a tool is invoked.\n",
    "\n",
    "_These are only dummy functions for simplicity in this example, but in a real use-case these functions would call an API or other method to actually perform an external task._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b19201-d16a-44cd-aa71-d9239085e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(city: str, state: str) -> str:\n",
    "    # call weather API...\n",
    "    return f\"It is 97 degrees Fahrenheit in {city}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9696c7bf-1f18-4d7a-b94c-c042ed51ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    # actually send email...\n",
    "    return f\"Successfully sent the following email: To: {to}\\nSubject: {subject}\\n{body}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bba045-9361-452c-8da4-e8e2b90def45",
   "metadata": {},
   "source": [
    "### Create system message and user query\n",
    "Messages are defined as dictionaries: `role` indicates who is speaking (e.g. system, user, assistant), and `content` contains what they say.\n",
    "\n",
    "The system message will instruct the LLM on how to act and respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0d8a16-6c55-4436-b8ac-0427a81c1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"You are a helpful assistant.\"\n",
    "}\n",
    "\n",
    "user_message = {\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"Should I dress for hot or cold weather in SF today?\"\n",
    "}\n",
    "\n",
    "messages=[\n",
    "    system_message,\n",
    "    user_message\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42844e21-f103-43ea-a902-d16a5702c27a",
   "metadata": {},
   "source": [
    "### Call completion to get tool call parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f514fd40-4535-437b-8017-b7fa18f81cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call_response = client.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58deadc-9adf-4c6e-ad08-19ba8ebc689f",
   "metadata": {},
   "source": [
    "### Run function with tool call parameters and give tool call + tool output back to model as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01fd0eb-fa3e-40d4-841a-2cdacdd5700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a helpful assistant.'}\n",
      "{'role': 'user', 'content': 'Should I dress for hot or cold weather in SF today?'}\n",
      "{'role': 'assistant', 'tool_calls': [ChatCompletionMessageToolCall(id='call_0_f5beb8df42944c9abf139b7f59b452fa', function=Function(arguments='{\"city\": \"San Francisco\", \"state\": \"CA\"}', name='get_current_weather'), type='function')]}\n",
      "{'role': 'tool', 'tool_call_id': 'call_0_f5beb8df42944c9abf139b7f59b452fa', 'content': 'It is 97 degrees Fahrenheit in San Francisco.'}\n"
     ]
    }
   ],
   "source": [
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"tool_calls\": tool_call_response.choices[0].message.tool_calls\n",
    "})\n",
    "\n",
    "for tool_call in tool_call_response.choices[0].message.tool_calls:\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    result = eval(name)(**args)\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"content\": str(result)\n",
    "    })\n",
    "\n",
    "for m in messages:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1a3c3-b02c-4736-8b18-a7fa6b17cca1",
   "metadata": {},
   "source": [
    "### Run chat completion for final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1252a04c-c765-4d7d-a152-a285b37f34e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the current temperature of 97 degrees Fahrenheit in San Francisco, you should dress for warm weather."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    delta = chunk.choices[0].delta.content or \"\"\n",
    "    print(delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2131160f-edf5-40d8-971c-cb253d365e4b",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "- https://docs.vllm.ai/en/stable/examples/online_serving/openai_chat_completion_client_with_tools.html\n",
    "- https://platform.openai.com/docs/guides/function-calling\n",
    "- https://huggingface.co/Salesforce/xLAM-2-3b-fc-r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
